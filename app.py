import streamlit as st
import requests
import pandas as pd
import google.generativeai as genai
import time
import json
import urllib.parse
import xml.etree.ElementTree as ET
import re
import jieba 
from wordcloud import WordCloud 
import matplotlib.pyplot as plt 
import os
import altair as alt 

# --- 1. è¨­å®šé é¢ ---
st.set_page_config(page_title="æˆ¿å¸‚è¼¿æƒ…é›·é” AI ç‰ˆ", page_icon="ğŸ ", layout="wide")

# --- 2. å´é‚Šæ¬„è¨­å®š ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    if 'valid_api_key' not in st.session_state:
        st.session_state.valid_api_key = st.secrets.get("GEMINI_API_KEY", None)
    if not st.session_state.valid_api_key:
        user_input_key = st.text_input("è«‹è¼¸å…¥ Google Gemini API Key", type="password")
        if st.button("âœ… é©—è­‰ä¸¦è¨­å®š", type="primary"):
            if not user_input_key: st.error("âŒ è«‹è¼¸å…¥å…§å®¹")
            else:
                try:
                    genai.configure(api_key=user_input_key)
                    list(genai.list_models()) 
                    st.session_state.valid_api_key = user_input_key
                    st.success("é©—è­‰æˆåŠŸï¼")
                    time.sleep(1)
                    st.rerun()
                except Exception as e: st.error(f"âŒ ç„¡æ•ˆ: {e}")
    else:
        st.success("âœ… API Key å·²è¨­å®š")
        if st.secrets.get("GEMINI_API_KEY") is None:
            if st.button("ğŸ”„ æ¸…é™¤/æ›´æ› Key"):
                st.session_state.valid_api_key = None
                st.rerun()
    st.divider()
    force_demo_ai = st.checkbox("ğŸ”§ å¼·åˆ¶ä½¿ç”¨æ¨¡æ“¬ AI çµæœ (Demoç”¨)", value=False)

# --- æ¨¡å‹æ™ºæ…§é¸æ“‡ ---
def get_best_model_name(api_key):
    try:
        genai.configure(api_key=api_key)
        all_models = list(genai.list_models())
        text_models = [m.name for m in all_models if 'generateContent' in m.supported_generation_methods]
        for m in text_models:
            if 'gemini-1.5-flash' in m: return m
        for m in text_models:
            if 'gemini-pro' in m: return m
        if text_models: return text_models[0]
        return "gemini-pro"
    except: return "gemini-pro"

# --- é»‘åå–®èˆ‡æ¨™é¡Œéæ¿¾ ---
BLOCKED_FORUM_IDS = [
    "f=214", "f=260", "f=261", # æ±½è»Š
    "f=565", "f=168", "f=738", # å®¶é›»
    "f=61", "f=37", "f=320",   # 3Cã€ç›¸æ©Ÿ
    "f=566", "f=770", "f=132"  # ç©¿æˆ´
]

# [ä¿®æ­£] æ“´å……è² é¢é—œéµå­—ï¼ŒåŒ…å«æ”¿æ²»èˆ‡éæˆ¿ç”¢é›œè¨Š
NEGATIVE_KEYWORDS = [
    "ç›¸æ©Ÿ", "é¡é ­", "é–‹ç®±", "æ‰‹æ©Ÿ", "è€³æ©Ÿ", "éŸ³éŸ¿", "å–‡å­", "å„²å­˜è£ç½®", "ç¡¬ç¢Ÿ", 
    "é¡¯å¡", "ç­†é›»", "è¢å¹•", "æ»‘é¼ ", "éµç›¤", "ç‰›è‚‰éºµ", "é£Ÿè¨˜", "éŠè¨˜", "æ”å½±", "æ‹æ”",
    "Nikon", "Sony", "Canon", "Samsung", "iPhone", "Android",
    "èœå–®", "äº¤è»Š", "ä¿é¤Š", "è©¦é§•", "ç¶­ä¿®", "å¾µæ±‚", "è»Šå‹",
    "æŸ¯æ–‡å“²", "è”£è¬å®‰", "å¼Šæ¡ˆ", "åœ–åˆ©", "é¸èˆ‰", "é»¨éƒ¨", "æ”¿æ²»"
]

def is_blocked_link(link):
    if not link: return True
    for fid in BLOCKED_FORUM_IDS:
        if fid in link: return True
    return False

def is_irrelevant_title(title):
    for kw in NEGATIVE_KEYWORDS:
        if kw.lower() in title.lower():
            return True
    return False

def get_topic_id(link):
    match = re.search(r't=(\d+)', link)
    if match: return int(match.group(1))
    return 0

# --- è‡ªå‹•ä¸‹è¼‰ä¸­æ–‡å­—å‹ ---
def download_font():
    font_filename = "ChineseFont.ttf" 
    if os.path.exists(font_filename):
        if os.path.getsize(font_filename) < 1000000: 
            os.remove(font_filename) 
        else:
            return font_filename 
    urls = [
        "https://raw.githubusercontent.com/google/fonts/main/ofl/notosanstc/NotoSansTC-Regular.ttf",
        "https://raw.githubusercontent.com/justfont/open-huninn-font/master/font/jf-openhuninn-1.1.ttf",
        "https://github.com/anthonyhilyard/GitHub-Chinese-Fonts/raw/master/WenQuanYiMicroHei.ttf"
    ]
    progress_text = "æ­£åœ¨ä¸‹è¼‰ä¸­æ–‡å­—å‹è³‡æº... (å˜—è©¦å¤šå€‹ä¾†æº)"
    my_bar = st.progress(0, text=progress_text)
    for i, url in enumerate(urls):
        try:
            my_bar.progress((i + 1) * 33, text=f"æ­£åœ¨å˜—è©¦ä¸‹è¼‰å­—å‹ä¾†æº {i+1}/3 ...")
            response = requests.get(url, timeout=60) 
            if response.status_code == 200:
                with open(font_filename, "wb") as f:
                    f.write(response.content)
                if os.path.getsize(font_filename) > 1000000:
                    my_bar.empty() 
                    return font_filename
        except: continue
    my_bar.empty()
    st.warning("æ‰€æœ‰å­—å‹ä¸‹è¼‰ä¾†æºå‡å¤±æ•—ï¼Œæ–‡å­—é›²å°‡ç„¡æ³•é¡¯ç¤ºä¸­æ–‡ã€‚")
    return None

# --- ç”¢ç”Ÿæ–‡å­—é›² ---
def generate_wordcloud(titles_list, user_keywords_str=""):
    text = " ".join(titles_list)
    stopwords = {
        "çš„", "äº†", "åœ¨", "æ˜¯", "æˆ‘", "æœ‰", "å’Œ", "å°±", "äºº", "éƒ½", "ä¸€å€‹", "ä¸Š", "ä¹Ÿ", "å¾ˆ", "åˆ°", "èªª", "è¦", "å»", "ä½ ",
        "æœƒ", "è‘—", "æ²’æœ‰", "çœ‹", "å¥½", "è‡ªå·±", "é€™", "è«‹å•", "è«‹ç›Š", "è¨è«–", "åˆ†äº«", "å•é¡Œ", "å¤§å®¶", "çŸ¥é“", 
        "Mobile01", "mobile01", "MOBILE01", "Moible01", 
        "ä»€éº¼", "æ€éº¼", "å¯ä»¥", "çœŸçš„", "å› ç‚º", "æ‰€ä»¥", "å¦‚æœ", "ä½†æ˜¯", "æ¯”è¼ƒ", "è¦ºå¾—", "ç¾åœ¨", "é‚„æ˜¯", "æœ‰æ²’æœ‰", "æ–‡ç« ",
        "æ¨™é¡Œ", "é€£çµ", "ä¾†æº", "ç™¼å¸ƒæ™‚é–“", "æˆ¿ç”¢", "å°åŒ—", "å°ç£", "è¨è«–å€", "å°ˆå€", "æ–°è", "å ±å°", "è¡¨ç¤º", "æŒ‡å‡º"
    }
    
    if user_keywords_str:
        for k in user_keywords_str.split():
            stopwords.add(k)
            
    try:
        hot_terms = [
            "é»ƒä»å‹³", "è¼é”", "NVIDIA", "å°ç©é›»", "åŒ—å£«ç§‘", "ç§‘å­¸åœ’å€", "è»Ÿé«”åœ’å€", 
            "é å”®å±‹", "æ–°é’å®‰", "é«˜éµ", "æ·é‹", "AI", "åŠå°é«”", "å–®åƒ¹", "ç¸½åƒ¹"
        ]
        for term in hot_terms:
            jieba.add_word(term)

        words = jieba.cut(text)
        filtered_words = [word for word in words if word not in stopwords and len(word) > 1]
        text_clean = " ".join(filtered_words)
        if not text_clean.strip(): return None 
        font_path = download_font()
        if font_path:
            wc = WordCloud(
                font_path=font_path, background_color="white", width=800, height=400, max_words=80, colormap="viridis", font_step=2, min_font_size=10
            ).generate(text_clean)
        else:
            wc = WordCloud(background_color="white", width=800, height=400, max_words=80).generate(text_clean)
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.imshow(wc, interpolation="bilinear")
        ax.axis("off")
        return fig
    except Exception as e:
        print(f"æ–‡å­—é›²ç¹ªè£½å¤±æ•—: {e}") 
        return None

# --- 3.1 æœå°‹ Mobile01 ---
def search_mobile01_via_google(keyword_input):
    if not keyword_input: 
        keyword_input = "å°åŒ— æˆ¿ç”¢"
        keywords = ["å°åŒ—", "æˆ¿ç”¢"]
    else:
        keywords = keyword_input.split()

    real_estate_terms = "é å”® OR å»ºæ¡ˆ OR æˆ¿åƒ¹ OR åªæ•¸ OR æ ¼å±€ OR å…¬å¯“ OR å¤§æ¨“ OR è±ªå®… OR ç½®ç”¢ OR è²·æˆ¿"
    
    if len(keywords) > 1:
        keyword_part = f"({' OR '.join(keywords)})"
    else:
        keyword_part = keyword_input
        
    search_query = f"{keyword_part} ({real_estate_terms}) site:mobile01.com when:1y"
    encoded_query = urllib.parse.quote(search_query)
    rss_url = f"https://news.google.com/rss/search?q={encoded_query}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
    try:
        response = requests.get(rss_url, timeout=10)
        root = ET.fromstring(response.content)
        articles = []
        items = root.findall('.//item')
        
        for item in items[:60]: 
            title = item.find('title').text if item.find('title') is not None else "ç„¡æ¨™é¡Œ"
            link = item.find('link').text if item.find('link') is not None else "#"
            pub_date = item.find('pubDate').text if item.find('pubDate') is not None else ""
            title = re.sub(r'(?i)\s*[-|]\s*mobile01', '', title).strip()
            
            if is_irrelevant_title(title): continue
            if not any(k in title for k in keywords): continue
            
            tid = get_topic_id(link)
            articles.append({"æ¨™é¡Œ": title, "é€£çµ": link, "ä¾†æº": "Mobile01", "ç™¼å¸ƒæ™‚é–“": pub_date, "topic_id": tid})
            
        articles.sort(key=lambda x: x['topic_id'], reverse=True)
        return articles[:10]
    except Exception as e:
        st.error(f"Mobile01 æœå°‹éŒ¯èª¤: {e}"); return []

# --- 3.2 æœå°‹ä¸€èˆ¬æ–°è ---
def search_general_news_via_google(keyword_input):
    if not keyword_input: return []
    keywords = keyword_input.split()
    
    if len(keywords) > 1:
        keyword_part = f"({' OR '.join(keywords)})"
    else:
        keyword_part = keyword_input
        
    search_query = f"{keyword_part} -site:mobile01.com -site:ptt.cc when:1y"
    encoded_query = urllib.parse.quote(search_query)
    rss_url = f"https://news.google.com/rss/search?q={encoded_query}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
    
    try:
        response = requests.get(rss_url, timeout=10)
        root = ET.fromstring(response.content)
        articles = []
        items = root.findall('.//item')
        
        for item in items[:20]:
            title = item.find('title').text if item.find('title') is not None else ""
            title = re.sub(r'\s*-\s*.*', '', title).strip()
            # é€™è£¡ä¹Ÿè¦éæ¿¾æ‰æ”¿æ²»é›œè¨Š
            if title and not is_irrelevant_title(title):
                articles.append(title)
        return articles
    except:
        return []

def get_demo_data():
    return [{"æ¨™é¡Œ": "åŒ—å£«ç§‘é å”®å±‹é–‹åƒ¹ç ´ç™¾è¬åˆç†å—ï¼Ÿå¿ƒå¾ˆç´¯", "é€£çµ": "https://www.mobile01.com/t=999"}]

# --- 4. AI åˆ†æ ---
def analyze_with_gemini(df, use_fake=False):
    current_key = st.session_state.valid_api_key
    is_simulated = use_fake or (not current_key)

    if is_simulated:
        time.sleep(1)
        fake_summary = f"ã€æ¨¡æ“¬å¿«å ±ã€‘é‡å°æœ¬æ¬¡æœå°‹çµæœï¼Œæ•´é«”å¸‚å ´æ°›åœåå‘è§€æœ›èˆ‡ç„¦æ…®..."
        demo_sentiments = ["ç„¦æ…®", "è² é¢", "æ­£é¢", "è§€æœ›", "ä¸­ç«‹"] * 3
        demo_keywords = ["åƒ¹æ ¼éé«˜", "æ¼æ°´ç–‘æ…®", "æ ¼å±€æ–¹æ­£", "é«˜é»å¥—ç‰¢", "é‡åŠƒå€ç™¼å±•"] * 3
        df['AIæƒ…ç·’'] = demo_sentiments[:len(df)]
        df['é—œéµé‡é»'] = demo_keywords[:len(df)]
        return df, fake_summary, None, True
    
    try:
        genai.configure(api_key=current_key)
        best_model = get_best_model_name(current_key)
        model = genai.GenerativeModel(best_model) 
        titles_text = "\n".join([f"{i+1}. {t}" for i, t in enumerate(df['æ¨™é¡Œ'].tolist())])
        
        prompt = f"""
        ä½ æ˜¯å°ˆæ¥­çš„æˆ¿åœ°ç”¢è¼¿æƒ…åˆ†æå¸«ã€‚è«‹é–±è®€ä»¥ä¸‹ Mobile01 è¨è«–å€çš„æ¨™é¡Œï¼š
        {titles_text}
        
        è«‹åŸ·è¡Œä»¥ä¸‹ä»»å‹™ï¼š
        1. åˆ¤æ–·æ¯ä¸€å€‹æ¨™é¡Œæ˜¯å¦èˆ‡ã€Œæˆ¿åœ°ç”¢ã€è³¼å±‹ã€å»ºæ¡ˆã€è£æ½¢ã€å±…ä½ã€ç›¸é—œã€‚
        2. å¦‚æœæ¨™é¡Œèˆ‡æˆ¿åœ°ç”¢ç„¡é—œï¼Œè«‹å°‡æƒ…ç·’è¨­ç‚ºã€Œéæˆ¿ç”¢ã€ï¼Œé—œéµå­—è¨­ç‚ºã€Œç„¡ã€ã€‚
        3. æ’°å¯«ã€Œå¸‚å ´è¼¿æƒ…å¿«å ±ã€(ç´„ 3-5 å¥è©±)ï¼Œåªç¸½çµèˆ‡æˆ¿åœ°ç”¢ç›¸é—œçš„å…§å®¹ã€‚
        
        è«‹ç›´æ¥å›å‚³ä¸€å€‹ JSON æ ¼å¼çš„è³‡æ–™ï¼Œæ ¼å¼å¦‚ä¸‹ï¼ˆä¸è¦ Markdown æ¨™è¨˜ï¼‰ï¼š
        {{
            "summary_report": "åœ¨é€™è£¡å¡«å¯«ä½ çš„å¸‚å ´è¼¿æƒ…å¿«å ±å…§å®¹...",
            "details": [
                {{"sentiment": "æ­£é¢/è² é¢/ä¸­ç«‹/ç„¦æ…®/è§€æœ›/éæˆ¿ç”¢", "keyword": "é—œéµå­—1, é—œéµå­—2"}}
            ]
        }}
        """
        response = model.generate_content(prompt)
        clean_text = response.text.replace("```json", "").replace("```python", "").replace("```", "").strip()
        try:
            result_json = json.loads(clean_text)
            summary_report = result_json.get("summary_report", "AI ç„¡æ³•ç”¢ç”Ÿç¸½çµå ±å‘Šã€‚")
            details = result_json.get("details", [])
        except:
            summary_report = "AI å›å‚³æ ¼å¼ç•°å¸¸ï¼Œç„¡æ³•è§£æç¸½çµå ±å‘Šã€‚"
            details = []
        sentiments = [item.get('sentiment', 'æœªçŸ¥') for item in details]
        keywords = [item.get('keyword', 'ç„¡') for item in details]
        while len(sentiments) < len(df):
            sentiments.append("æœªçŸ¥"); keywords.append("ç„¡")
        df['AIæƒ…ç·’'] = sentiments[:len(df)]
        df['é—œéµé‡é»'] = keywords[:len(df)]
        
        df_filtered = df[df['AIæƒ…ç·’'] != 'éæˆ¿ç”¢'].reset_index(drop=True)
        return df_filtered, summary_report, None, False 
    except Exception as e:
        return df, "", str(e), False

# --- 5. ä¸»ç¨‹å¼ä»‹é¢ ---
st.title("ğŸ  æˆ¿å¸‚è¼¿æƒ…é›·é” + AI æ´å¯Ÿ") 

if 'data' not in st.session_state: st.session_state.data = []
if 'news_data' not in st.session_state: st.session_state.news_data = [] 
if 'analyzed_data' not in st.session_state: st.session_state.analyzed_data = None
if 'summary_report' not in st.session_state: st.session_state.summary_report = ""

st.write("### ğŸ” è¼¿æƒ…é—œéµå­—æœå°‹")
col_input, col_btn = st.columns([3, 1])
with col_input:
    keyword = st.text_input("è¼¸å…¥é—œéµå­— (å¯å¤šçµ„ï¼Œä¾‹å¦‚ï¼šåŒ—å£«ç§‘ å£«æ—)", "åŒ—å£«ç§‘")
with col_btn:
    st.write(""); st.write("")
    if st.button("ğŸš€ æœå°‹æœ€æ–°è©±é¡Œ", type="primary"):
        with st.spinner(f'æ­£åœ¨é€²è¡Œé›™è»Œæœå°‹ï¼šMobile01 è¨è«– + ç›¸é—œæ–°è...'):
            st.session_state.data = search_mobile01_via_google(keyword)
            st.session_state.news_data = search_general_news_via_google(keyword)
            st.session_state.analyzed_data = None
            st.session_state.summary_report = ""
            if not st.session_state.data: 
                st.warning(f"Mobile01 æ‰¾ä¸åˆ°ç›¸é—œè¨è«–ï¼Œä½†æˆ‘å€‘å˜—è©¦æŠ“å–æ–°èã€‚")

if st.button("ğŸ“‚ è¼‰å…¥ç¯„ä¾‹è³‡æ–™ (Demo)", help="æœå°‹ä¸åˆ°æ™‚ä½¿ç”¨"):
    st.session_state.data = get_demo_data()
    st.session_state.news_data = ["åŒ—å£«ç§‘æˆ¿åƒ¹å‰µæ–°é«˜", "é»ƒä»å‹³ä¾†å°å¸¶å‹•AIåœ’å€ç™¼å±•", "è¼é”è¨­å» åœ°é»æ›å…‰"] 
    st.session_state.analyzed_data = None 
    st.success("å·²è¼‰å…¥æ¨¡æ“¬æ•¸æ“šï¼")

# --- 6. é¡¯ç¤ºå…§å®¹å€ ---
if st.session_state.data or st.session_state.news_data:
    df = pd.DataFrame(st.session_state.data) if st.session_state.data else pd.DataFrame()
    st.divider()
    
    tab1, tab2 = st.tabs(["ğŸ“‹ åŸå§‹è©±é¡Œåˆ—è¡¨", "ğŸ“Š AI æ´å¯Ÿå ±å‘Š & æ–‡å­—é›²"])
    
    with tab1: 
        if not df.empty:
            st.write(f"å…±è’é›† {len(df)} å‰‡ Mobile01 è©±é¡Œ")
            st.dataframe(df[['æ¨™é¡Œ', 'é€£çµ']], 
                         column_config={"é€£çµ": st.column_config.LinkColumn("æ–‡ç« é€£çµ")},
                         use_container_width=True)
        else:
            st.info("Mobile01 æš«ç„¡è³‡æ–™ã€‚")
        st.info("ğŸ‘‰ é»æ“Šä¸Šæ–¹ã€ŒğŸ“Š AI æ´å¯Ÿå ±å‘Šã€åˆ†é ï¼Œå•Ÿå‹• AI åˆ†æåŠŸèƒ½")

    with tab2: 
        st.write("### ğŸ§  AI è¼¿æƒ…åˆ†æä¸­å¿ƒ")
        
        if st.session_state.analyzed_data is None: 
            if st.button("ğŸ¤– å•Ÿå‹• AI å…¨é¢è§£è®€ (åŒ…å«æ–‡å­—é›²)", type="primary"):
                with st.spinner("AI æ­£åœ¨é–±è®€è¨è«–ä¸²ã€ä¸¦æ ¹æ“šã€Œç›¸é—œæ–°èã€ç¹ªè£½æ–‡å­—é›²..."):
                    if not df.empty:
                        result_df, summary, error, is_sim = analyze_with_gemini(df, use_fake=force_demo_ai)
                        st.session_state.analyzed_data = result_df
                        st.session_state.summary_report = summary
                        st.session_state.is_simulated = is_sim
                        st.session_state.error_msg = error
                    else:
                        st.session_state.analyzed_data = pd.DataFrame()
                        st.session_state.summary_report = "ç„¡ Mobile01 è¨è«–æ•¸æ“šï¼Œåƒ…æä¾›æ–°èæ–‡å­—é›²åƒè€ƒã€‚"
                        st.session_state.is_simulated = False
                        st.session_state.error_msg = None
                    st.rerun()
        
        if st.session_state.summary_report: 
            st.markdown("""---""")
            st.subheader("ğŸ“ AI å¸‚å ´è¼¿æƒ…å¿«å ± (åŸºæ–¼ Mobile01)")
            st.info(st.session_state.summary_report, icon="ğŸ’¡")
            
            st.markdown("""---""")
            col_wc, col_chart = st.columns([3, 2])
            
            with col_wc:
                st.subheader("â˜ï¸ è¶¨å‹¢ç†±é»æ–‡å­—é›² (åŸºæ–¼æ–°è)")
                try:
                    source_titles = st.session_state.news_data if st.session_state.news_data else df['æ¨™é¡Œ']
                    if source_titles and len(source_titles) > 0:
                        wc_fig = generate_wordcloud(source_titles, keyword)
                        if wc_fig:
                            st.pyplot(wc_fig)
                            st.caption(f"è³‡æ–™ä¾†æºï¼šGoogle News ({len(source_titles)} å‰‡)")
                        else:
                            st.warning("æ–‡å­—é›²ç”¢ç”Ÿå¤±æ•—ã€‚")
                    else:
                        st.warning("ç„¡è¶³å¤ æ–°èè³‡æ–™å¯ç¹ªè£½æ–‡å­—é›²ã€‚")
                except Exception as wc_error:
                     st.warning(f"æ–‡å­—é›²æš«æ™‚ç„¡æ³•é¡¯ç¤º")

            with col_chart:
                st.subheader("ğŸ“ˆ æƒ…ç·’åˆ†ä½ˆ (åŸºæ–¼ Mobile01)")
                if st.session_state.analyzed_data is not None and not st.session_state.analyzed_data.empty:
                    display_df = st.session_state.analyzed_data
                    if 'AIæƒ…ç·’' in display_df.columns:
                        chart_data = display_df['AIæƒ…ç·’'].value_counts().reset_index()
                        chart_data.columns = ['æƒ…ç·’', 'æ•¸é‡']
                        chart = alt.Chart(chart_data).mark_bar().encode(
                            x=alt.X('æƒ…ç·’', axis=alt.Axis(labelAngle=0, title='æƒ…ç·’é¡å‹')), 
                            y=alt.Y('æ•¸é‡', axis=alt.Axis(title='æ–‡ç« æ•¸é‡')),
                            color=alt.value('#1f77b4'),
                            tooltip=['æƒ…ç·’', 'æ•¸é‡']
                        ).properties(height=300)
                        st.altair_chart(chart, use_container_width=True)
                else:
                    st.info("ç„¡è¨è«–æ•¸æ“šé¡¯ç¤ºåœ–è¡¨")

            if st.session_state.analyzed_data is not None and not st.session_state.analyzed_data.empty:
                st.markdown("""---""")
                st.subheader("ğŸ” è©³ç´°åˆ†ææ•¸æ“š")
                with st.expander("é»æ“Šå±•é–‹æŸ¥çœ‹é€ç­†åˆ†æçµæœ"):
                    st.dataframe(
                        st.session_state.analyzed_data[['é€£çµ', 'æ¨™é¡Œ', 'AIæƒ…ç·’', 'é—œéµé‡é»']], 
                        column_config={
                            "é€£çµ": st.column_config.LinkColumn("å‰å¾€"), 
                            "AIæƒ…ç·’": st.column_config.TextColumn("æƒ…ç·’"),
                        },
                        use_container_width=True
                    )
else:
    st.info("ğŸ‘ˆ è«‹å…ˆåœ¨å·¦å´è¼¸å…¥é—œéµå­—ä¸¦æœå°‹")
